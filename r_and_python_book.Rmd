--- 
title: 'An Introduction to R and Python For Data Analysis: A Side By Side Approach'
author: "Taylor R. Brown"
site: bookdown::bookdown_site
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
documentclass: krantz
lot: yes
lof: yes
fontsize: 12pt
monofont: "Source Code Pro"
monofontoptions: "Scale=0.7"
bibliography:
- book.bib
- packages.bib
biblio-style: apalike
link-citations: yes
github-repo: tbrown122387/r_and_python_book
---

# Welcome {-}

Placeholder


## A Sample Course {-}
## License(s) {-}

<!--chapter:end:index.Rmd-->


# Preface {-}

Placeholder


## About this book {-}
## Conventions {-}
## Installing the Required Software {-}
### Installing R (and RStudio) {-}
### Installing Python by Installing Anaconda {-} 

<!--chapter:end:preface.Rmd-->


# (PART) Introducing the Basics {-} 

Placeholder


## Hello World in R
## Hello World in Python
## Getting Help
### Reading Documentation
### Understanding File Paths

<!--chapter:end:01-intro.Rmd-->


# Basic Types

Placeholder


## Basic Types In Python
### Type Conversions in Python
## Basic Types In R
### Type Conversions in R
### R's Simplification
## Exercises
### R Questions
### Python Questions

<!--chapter:end:02-basic_types.Rmd-->


# R `vector`s versus Numpy `array`s and Pandas' `Series`

Placeholder


## Overview of R
## Overview of Python
## Vectorization in R
## Vectorization in Python
## Indexing Vectors in R
## Indexing Numpy arrays
## Indexing Pandas' Series
## Some Gotchas
### Shallow versus Deep Copies
### How R and Python Handle Missing Values
## Exercises
### R Questions
### Python Questions

<!--chapter:end:03-vectors_and_arrays.Rmd-->


# Numpy `ndarray`s Versus R's `matrix` and `array` Types

Placeholder


## Numpy `ndarray`s In Python
## The `matrix` and `array` classes in R
## Exercises
### R Questions
### Python Questions

<!--chapter:end:04-arrays_and_matrices.Rmd-->


# R's `list`s Versus Python's `list`s and `dict`s

Placeholder


## `list`s In R
## `list`s In Python
## Dictionaries In Python
## Exercises
### R Questions
### Python Questions

<!--chapter:end:05-lists_and_dictionaries.Rmd-->


# Functions

Placeholder


## Defining R Functions
## Defining Python Functions
## More Details On R's User-Defined Functions
## More details on Python's user-defined functions
## Function Scope in R
## Function Scope in Python
## Modifying a Function's Arguments
### Passing By Value In R
### Passing By Assignment In Python
## Accessing and Modifying Captured Variables
### Accessing Captured Variables in R
### Accessing Captured Variables in Python
### Modifying Captured Variables In R
### Modifying Captured Variables In Python
## Exercises
### R Questions
### Python Questions

<!--chapter:end:06-functions.Rmd-->


# Categorical Data 

Placeholder


## `factor`s in R
## Two Options for Categorical Data in Pandas 
## Exercises
### R Questions
### Python Questions

<!--chapter:end:07-categorical_data.Rmd-->


# Data Frames

Placeholder


## Data Frames in R
## Data Frames in Python

<!--chapter:end:08-data_frames.Rmd-->

# (PART) Common Tasks and Patterns {-} 

# Input and Output


## General Input Considerations

So far we have been creating small pieces of data within our scripts. This is primarily for pedagogical purposes. In real life, we can have 

- data read in from a data set saved on our machine's hard drive (e.g. `my_data.csv` or `log_file.txt` ),
- data read in from a database (e.g. MySQL, PostgreSQL, etc.), or
- data created in a script (either deterministic or random).

I focus mostly on the first category in this section. Here are my reasons for doing so:

1. text-files are more readily-available to students than databases, 
2. teaching the second category requires teaching SQL, and that would introduce conceptual overlap, 
3. the third category is programmatically self-explanatory, and
4. reading in data from text files is more difficult than querying from a database.

::: {.rmd-details}
The third reason does not imply data created by code is unimportant. For example, it is the most common approach to create data used in **simulation studies.** Authors writing statistical papers need to demonstrate that their techniques work on "nice" data: data simulated from a *known* data-generating process. In a simulation study, unlike in the "real-world," you have access to the parameters generating your data, and you can examine data that might otherwise be unobserved or hidden. Further, with data from the real-world, there is no guarantee your model correctly matches the true model. 

Can your code/technique/algorithm, at the very least, obtain parameter estimates that are "in-line" with the parameters your code is using to simulate data? Are forecasts or predictions obtained by your method accurate? These kinds of questions can often only be answered by simulating fake data. Programmatically, simulating data like this largely involves calling functions that we have seen before (e.g. `rnorm()` in R or `np.random.choice()` in Python). This may or may not involve setting a pseudorandom number seed, first, for reproducibility. 

Also, *benchmark data sets* are often readily available through specialized function calls. 
:::


Even though this chapter is written to teach you how to read in files into R and Python, you should not expect that you will know how to read in *all* data sets after reading this section. For both R and Python, there are an enormous amount of functions, different functions have different return types, different functions are suited for different file types, many functions are spread across a plethora of third party libraries, and many of these functions have an enormous amount of arguments. You will probably not be able to memorize everything. In my very humble opinion, I doubt you should want to.

Instead, **focus on developing your ability to identify and diagnose data input problems.** Reading in a data set correctly is often a process of trial-and-error. After attempting to read in a data set, always check the following items. Many of these points were previously mentioned in section \@(data-frames-in-r). Some apply to reading in text data more than reading in structured data from a database, and vice versa. 

1. Check that **the correct column *separator* was used, or the correct "fixed-width format" was expected.** If mistakes are made, data frame columns are going to be combined or split apart in weird ways, and often the wrong types are going to be used for pieces of data (e.g. `"2,3"` instead of `2` and `3`.) Also, watch out for when separators are found inside data elements or column names. For example, sometimes it's unclear whether people's names in the "last, first" format can be stored in one or two columns. Also, text data might surprise you with unexpected spaces or other whitespace is a common separator.
2. Check that **the column names were parsed and stored correctly.** Column names should not be stored as data in R/Python. Functions that read in data should not expect column names when they don't exist in the actual file. 
3. Check that **empty space and metadata was ignored correctly.** Data descriptions are sometimes stored in the same file as the data itself, and that should be skipped over when it's being read in. Empty space between column names and data shouldn't be stored. This can occur at the beginning of the file, and even at the end of the file. 
4. **Type choice is performed correctly.** Are letters stored as strings or as something else such as an R `factor`? Are dates and times stored as a special date/time type, or as strings? Is missing data correctly identified? Sometimes data providers use outrageous numbers like $-9999$ to represent missing data--don't store that as a float or integer!


I realize that this is no small task. To make matters worse:

- you can't (or shouldn't) edit the raw data to suit your needs, to make it easier to read in. You have to work with what you are given. If you were allowed to edit, say, a text file you downloaded onto your own machine, you shouldn't--it will lead to code that doesn't run anywhere else. If you abuse write privileges on your company's database, for example--that could be very dangerous. 

- Data sets are often quite large, so manually checking each element is often impossible. In this situation you will have to resign yourself to checking the top and bottom of a data set, or maybe anticipate a specific place where problems are likely to appear. 


## Reading in Text Files with R 

You've seen examples of `read.csv()` used earlier in the book, so it should not surprise you that this is one of the most common ways to read in data in R. Another important function is `read.table()`. Actually, if you look at the source code for `read.csv()` (type the name of the function without parentheses into the console and press the `<Enter>` key), you will see it calls `read.table()`. The primary difference between these functions is default arguments. **Mind the default arguments.** Do not be completely averse to writing a long-line of code to read in a data set correctly. Or do, and choose the function with the best default arguments.

Consider the ["Challenger USA Space Shuttle O-Ring Data Set"](https://archive.ics.uci.edu/ml/datasets/Challenger+USA+Space+Shuttle+O-Ring) from [@uci_data]. The first ten rows of the text file looks like this.

```{bash, echo=FALSE, comment = NA}
head data/o-ring-erosion-only.data
```

It does not use commas as separators, and there is no header information, so `read.csv()` used with its default arguments will produce an incorrect result. It will miss the first row by counting it as a column name, and store everything in one column with the wrong type.

```{r, collapse = TRUE}
d <- read.csv("data/o-ring-erosion-only.data")
str(d)
typeof(d[,1])
```
Specifying `header=FALSE` fixes the column name issue, but `sep = " "` does not fix the separator issue.

```{r, collapse = TRUE}
d <- read.csv("data/o-ring-erosion-only.data", header=FALSE, sep = " ")
str(d)
```

One space is strictly one space. Some rows have two, though. After digging into the documentation a bit further, you will notice that `""` works for "one or more spaces, tabs, newlines or carriage returns." This is why `read.table()`, with its default arguments, works well. 

```{r, collapse = TRUE}
d <- read.table("data/o-ring-erosion-only.data")
str(d)
```
This data set has columns whose widths are "fixed", too. It is in "fixed width format" because any given column has all its elements take up a constant amount of characters. The third column has integers with two or three digits, but no matter what, each row has the same number of characters. The annoying thing about this method, though, is you have to specify what those widths are. This can be quite tedious if your data set has many columns and/or many rows. The upside though, is that the files can be a little bit smaller, because the data provider does not have to waste characters on separators.

```{r, collapse = TRUE}
d <- read.fwf("data/o-ring-erosion-only.data", widths = c(1,1,2,3,2), sep = "")
str(d)
```

If you need to read in some text data that does not possess a tabular structure, then you may need `readLines()`. This function will read in all of the text, separate each line into an element of a `character` `vector`, and will not make any attempt to parse lines into columns. Further processing can be accomplished using the techniques from chapter \@(working-with-text-data).

```{r, collapse=TRUE}
html_data <- readLines("data/Google.html", warn = FALSE)
head(html_data, 2)
```


## Reading in Text Files with Pandas

A [wide variety of different file formats can be read in with Pandas.](https://pandas.pydata.org/pandas-docs/stable/reference/io.html) I will only mention a few functions here. 

Recall R has `read.table()` and `read.csv()`, and that they are very similar. In Pandas, [`pd.read_csv()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) and [`pd.read_table()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_table.html) have a lot in common, too. Their primary difference is the default column separator. 

Recall the O-Ring data from above. The columns are *not* separated by commas, so if we treat it as a comma-separated file, the resulting Pandas `DataFrame` is going to be missing all but one of its columns. 

```{python, collapse = TRUE}
import pandas as pd
d = pd.read_csv("data/o-ring-erosion-only.data")
d.head(2)
d.shape
d.columns
```

By default, `pd.read_csv()` is expecting column labels, which is also a problem. Unlike R, though, the `header=` argument is not expected to be a Boolean. You will need to provide a `None` object, instead. The separator needs to be just right, too. 


```{python, collapse = TRUE}
pd.read_csv("data/o-ring-erosion-only.data", header=None, sep = " ").head(2) # 1 space: no
pd.read_csv("data/o-ring-erosion-only.data", header=None, sep = "\t").head(2) # tabs: no
pd.read_csv("data/o-ring-erosion-only.data", header=None, sep = "\s+").head(2) # 1 or more spaces: yes
pd.read_table("data/o-ring-erosion-only.data").head(2) # also yes
```

<!-- One space is strictly one space. Some rows have two, though. After digging into the documentation a bit further, you will notice that `""` works for "one or more spaces, tabs, newlines or carriage returns." This is why `read.table()`, with its default arguments, works well.  -->

```{r, collapse = TRUE}
pd.read_csv("data/o-ring-erosion-only.data", header=None, sep = " ")

d <- read.table("data/o-ring-erosion-only.data")
str(d)
```
<!-- This data set has columns whose widths are "fixed", too. It is in "fixed width format" because any given column has all its elements take up a constant amount of characters. The third column has integers with two or three digits, but no matter what, each row has the same number of characters. The annoying thing about this method, though, is you have to specify what those widths are. This can be quite tedious if your data set has many columns and/or many rows. The upside though, is that the files can be a little bit smaller, because the data provider does not have to waste characters on separators. -->

<!-- ```{r, collapse = TRUE} -->
<!-- d <- read.fwf("data/o-ring-erosion-only.data", widths = c(1,1,2,3,2), sep = "") -->
<!-- str(d) -->
<!-- ``` -->

<!-- If you need to read in some text data that does not possess a tabular structure, then you may need `readLines()`. This function will read in all of the text, separate each line into an element of a `character` `vector`, and will not make any attempt to parse lines into columns. Further processing can be accomplished using the techniques from chapter \@(working-with-text-data). -->

<!-- ```{r, collapse=TRUE} -->
<!-- html_data <- readLines("data/Google.html", warn = FALSE) -->
<!-- head(html_data, 2) -->
<!-- ``` -->


## Output

After we have created something useful, we might be interested in storing our results. We can write out to a database, a text file, or we can save a digitized version of our work space.


TODO serialization
TODO

<!--chapter:end:09-io.Rmd-->


# Using Third-Party Code

Placeholder


## Installing Packages In R 
## Installing Packages In Python 
## Loading Packages In R 
## Loading Packages In Python 
### `import`ing Examples

<!--chapter:end:10-third_party_code.Rmd-->


# Control Flow

Placeholder


## Conditional Logic 
## Loops
## A Longer Example
### Description of Accept-Reject Sampling
### A Specific Example

<!--chapter:end:11-control_flow.Rmd-->


# Reshaping and Combining Data Sets

Placeholder


## Ordering and Sorting Data
## Stacking Data Sets and Placing Them Shoulder to Shoulder
## Merging or Joining Data Sets
## Long Versus Wide Data
### Long Versus Wide in R
### Long Versus Wide in Python

<!--chapter:end:12-reshaping.Rmd-->


# Visualization

Placeholder


## Base R Plotting
## Plotting with `ggplot2`
## Plotting with Matplotlib

<!--chapter:end:13-visualization.Rmd-->

# Working With Text Data

TODO

- regular expressions


<!--chapter:end:14-text_data.Rmd-->

# Dates and Times

TODO


<!--chapter:end:15-dates_and_times.Rmd-->

# Running Scripts from the Command Line

TODO


<!--chapter:end:16-CLI.Rmd-->


# (PART) Programming Styles {-} 

Placeholder


## OOP In Python
### Overview
### A First Example
### Adding Inheritance
### Adding in Composition
## OOP In R
### S3 objects: The Big Picture
### Using S3 objects
### Creating S3 objects
### S4 objects: The Big Picture
### Using S4 objects
### Creating S4 objects
### Reference Classes: The Big Picture
### Creating Reference Classes
### Creating R6 Classes
## Exercises

<!--chapter:end:17-oop.Rmd-->


# Functional Programming

Placeholder


## Functions as Function Inputs in R
### `sapply()` and `vapply()`
### `lapply()`
### `apply()`
### `tapply()`
### `mapply()`
### `Reduce()` and `do.call()`
## Another Example in R
## Functions as Function Inputs in Base Python
### `map()`
### `filter()`
## Functions as Function Inputs in Numpy
## Functional Methods in Pandas
## Functions as Function Inputs (miscellany)
## Functions as Function Outputs in R
## Functions as Function Outputs in Python

<!--chapter:end:18-FP.Rmd-->

