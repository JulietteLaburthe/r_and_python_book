# Data Types 

In every programming language, data is stored in different ways. Writing a program that manipulates data requires understanding all of the choices. That is why we must be concerned with the different **types** of data in our `R` and `Python` programs. Different types are suitable for different purposes.

There are similarities between `Python`'s and `R`'s type systems. However, there are may  differences as well. Be prepared for these differences. There are many more of them in this chapter than there were in the previous chapter!

If you're ever unsure what type a variable has, use `type()` (in `Python`) or `typeof()` (in `R`) to query it. 


<!---
---------------------------------------------------------------------------
-->


## Basic Types

Storing an individual piece of information is simple in both languages. However, while `Python` has scalar types, `R`'s situation is a little more complicated (TODO word choice).

### In `Python`

In `Python`, the simplest types we frequently use are `str` (short for string), `int` (short for integer), `float` (short for floating point) and `bool` (short for Boolean). This list is not exhaustive, but these are a good collection to start thinking about. For a complete list of built-in types in `Python`, click [here](https://docs.python.org/3/library/stdtypes.html).

```{python, collapse = TRUE}
print(type('a'), type(1), type(1.3))
```

Strings are useful for processing text data such as names of people/places/things and messages (e.g. texts, tweets and emails). If you are dealing with numbers, you need floating points if you have a number that might have a fractional part after its decimal; otherwise you'll need an integer. Booleans are useful for situations where you need to record whether something is true or false. They are also important to understand for control-flow (TODO which section).

In the next section we will discuss the Numpy library. This library has a [broader collection](https://numpy.org/doc/stable/user/basics.types.html) of basic types. 

#### Type Conversions

We will often have to convert between types in a `Python` program. This is called **type conversion**, and it can be either implicitly or explicitly done. 
For example, `int`s are often implicitly converted to `float`s, so that arithmetic operations work. 
```{python, collapse = TRUE}
my_int = 1
my_float = 3.2
my_sum = my_int + my_float
print("my_int's type", type(my_int))
print("my_float's type", type(my_float))
print(my_sum)
print("my_sum's type", type(my_sum))
```

You might be disappointed if you always count on this behavior, though.
```{python, error = TRUE, collapse=TRUE}
3.2 + "3.2"
```

Explicit conversions occur when we as programmers are explicitly asking `Python` to perform the conversion. You will do this with the functions `int()`, `str()`, `float()`, `bool()`, and the like. 

```{python, collapse = TRUE}
my_date = "5/2/2021"
month_day_year = my_date.split('/')
my_year = int(month_day_year[-1]) 
print('my_year is equal to ', my_year, 'and its type is ', type(my_year))
```

### In `R`

In `R`, the names of these basic types are only slightly different. They are `logical` (instead of `bool`), `integer` (instead of `int`), `double` (instead of `float`)^["double" is short for "double precision floating point." In the programming language `C`, which is what both `R` and `Python` are written in, the programmer has more control on how many decimal points of precision he wants.], and `character` (instead of `str`). There is also `complex` and `raw`, but we will use these less often in this textbook.

```{R, collapse = TRUE}
# cat() is kind of like print()
cat(typeof('a'), typeof(1), typeof(1.3))
```

In this case `R` automatically upgraded `1` to a double. If you wanted to force it to be an integer, you can add a capital "L" to the end of the number.

```{R, collapse = TRUE}
# cat() is kind of like print()
cat(typeof('a'), typeof(1L), typeof(1.3))
```


#### Type Conversions

You can explicitly and implicitly convert types in `R` just as you did in `Python`. Implicit conversion looks like this.

```{R, collapse = TRUE}
myInt = 1
myDouble = 3.2
mySum = myInt + myDouble
print(paste0("my_int's type is ", typeof(myInt)))
print(paste0("my_float's type is ", typeof(myDouble)))
print(mySum)
print(paste0("my_sum's type is ", typeof(mySum)))
```

Explicit conversion can be achieved with functions such as `as.integer`, `as.logical`, `as.double`, etc.

```{R, collapse = TRUE}
print(typeof(1))
print(typeof(as.logical(1)))
```



#### What was the weird thing about `R` you mentioned?

The basic types of `R` are a little different than the basic types of `Python`. `R` uses the same type to store many elements. It does not have any scalar type. On the other hand, `Python` has base types for individual elements, and it uses separate types as containers for storing many elements. In `R`, if you are looking at single number or character string, it's actually a length $1$ `vector`. More information about `vector`s in TODO.

TODO constants versus literals?

<!---
---------------------------------------------------------------------------
-->


## `R` vectors versus `numpy` arrays (and Pandas `Series`)

This section is for describing the data types that let us store collections of elements that all **share the same type**. Data is very commonly stored in this fashion, so this section is quite important. Once we have one of these objects in a program, we will be interested in learning how to extract different subsets of elements, and how vectorization works

### Overview of `R`

I mentioned earlier that `R` does not have scalar types--it just has [**vectors**](https://cran.r-project.org/doc/manuals/r-release/R-lang.html#Vector-objects
). So, whether you want to store one number, or many numbers, you will need a `vector`. 

How do we create one of these? There are many ways. One common is to read in elements from an external data set, perhaps extracting them from a column of a `data.frame`, but we will describe those in section TODO. Here are some examples of generating `vector`s from code instead of external data sets.

```{R, collapse = TRUE}
1:10
seq(1,10,2)
rep(2,5)
c("5/2/2021", "5/3/2021", "5/4/2021")
rnorm(10)
```

`c` is short for "combine". `seq` and `rep` are short for "sequence" and "replicate", respectively. `rnorm` samples normal (or Gaussian) random variables. There is plenty more to learn about these functions, so I encourage you to take a look at their documentation.

### Overview of `Python`

If you want to store many elements of the same type (and size) in `Python`, you will need a Numpy `array`. Numpy is a very highly-regarded third party library [@harris2020array]

There are five ways to create numpy arrays ([source](https://numpy.org/doc/stable/user/basics.creation.html)). Here are some examples that complement the above examples.

```{python, collapse = TRUE}
import numpy as np
np.array([1,2,3])
np.arange(1,12,2)
np.random.normal(size=3)
```

Another choice in `Python` is to use [`Series` object](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas-series). These are made available through the Pandas library. The benefit of these is that they play nicely with Pandas Data frames (TODO link), and that they have more flexibility with accessing elements by name (cite book https://jakevdp.github.io/PythonDataScienceHandbook/03.01-introducing-pandas-objects.html#Series-as-generalized-NumPy-array).

### Vectorization in `R`

An operation is **vectorized** if it applies to all of the elements of a `vector` at once. An operator that is not vectorized can only be applied to individual elements. In that case, the programmer would need to write more code to instruct the function to be applied to all of the elements of a vector. You should prefer writing vectorized code because it is easier to read, and quite often it runs much faster.

Arithmetic (e.g. `+`, `-`, `*`, `/`, `^`, `%%`, `%/%`, etc.) and logical (e.g. `!`, `|`, `&`, `>`, `>=`, `<`, `<=`, `==`, etc.) operators  are commonly applied on single vectors or between two vectors. Numeric vectors are converted to logical vectors if they need to be. Many functions work on vectors **element-wise** as well (except functions like `sum` or `length`, etc.). Operator precedence is important to understand if you seek to minimize your use of parentheses. Here are some examples.

```{r, collapse = TRUE}
(1:3) * (1:3)
(1:3) == rev(1:3)
sin( (2*pi/3)*(1:5))
```

In the last example, there is **recycling** happening. `(2*pi/3)` is taking three length-one vectors and producing another length-one vector. That gets multiplied by length five vector `1:5`. The single element in the length one vector gets recycled so that its value is multiplied by every element of `1:5`. 
This makes sense most of the time, but sometimes it can be tricky. Notice that this does not produce an error--just a warning.
```{r, collapse = TRUE}
(1:3) * (1:4)
```

### Vectorization in `Python`

TODO add pandas series

`Python`'s Numpy library makes extensive use of vectorization as well. Vectorization in Numpy is accomplished with [**universal functions**](https://numpy.org/doc/stable/reference/ufuncs.html), or `ufunc` for short. Some `ufunc`s can be invoked using the same syntax as in `R` (e.g. `+`). You can also refer to function by name (e.g. `np.sum`). Mixing and matching is allowed, too.

`ufunc`s are called unary if they take in one array, and binary if they take in two. I reproduce a portion of the very nice table found in [@py_ds_handbook] 

| Operator |	Equivalent `ufunc` |
|-----------|-------------------|
`+`	| `np.add`	
`-`	| `np.subtract`	
`-`	| `np.negative`	
`*` |	`np.multiply`	
`/`	| `np.divide`	
`//` |	`np.floor_divide`	
`**`	| `np.power`	
`%` |	`np.mod`

For an exhaustive list of Numpy's universal functions, [click here.](https://numpy.org/doc/stable/reference/ufuncs.html#available-ufuncs) Here are some examples.


```{python, collapse=TRUE}
np.arange(1,4)*np.arange(1,4)
np.zeros(5) > np.arange(-3,2)
np.exp( -.5 * np.linspace(-3, 3, 10)**2) / np.sqrt( 2 * np.pi)
```

Instead of calling it "recycling", `Python` calls it [**broadcasting**](https://numpy.org/devdocs/user/theory.broadcasting.html). It's the same idea as in `R`, but in general, `Python` is stricter and disallows more scenarios. 

### Indexing `vector`s in `R`

It is very common to want to extract or modify a subset of elements in a vector. There are a few ways to do this. All of them involve the square bracket operator (e.g. `[]`). Feel free to retrieve the documentation by typing `?'['`.

```{R, collapse = TRUE}
allElements <- 1:6
allElements[seq(2,6,2)] # extract evens
allElements[-seq(2,6,2)] <- 99 # replace all odds with 99
allElements[allElements > 2] # get nums bigger than 20
```

To access the first element, we use the index `1`. To access the second, we use `2`, and so on. Also, the `-` sign tells `R` to remove elements. Both of these functionalities are *very different* from `Python`, as we will see shortly.

We can use names to access elements elements, too, but only if the elements are named.

```{R, collapse = TRUE}
sillyVec <- c("favorite"=1, "least favorite" = 2)
sillyVec['favorite']
```


### Indexing Numpy arrays

[Indexing Numpy arrays](https://numpy.org/doc/stable/user/basics.indexing.html) is very similar to indexing vectors in `R`. You use the square brackets, and you can do it with logical arrays or index arrays. There are some important differences, though. 

For one, indexing is 0-based in `Python`. The `0`th element is the first element of an array. Another key difference is that the `-` isn't used to remove elements like it is in `R`, but rather to count backwards. Third, using `:`inside square brackets is more flexible in `Python` (e.g. you can get **striding** functionality without using `seq`).

```{python, collapse=TRUE}
one_through_ten = np.arange(1, 11)
one_through_ten[np.array([2,3])]
one_through_ten[1:10:2] # evens
one_through_ten[-2] = 99 # second to last
one_through_ten
one_through_ten[one_through_ten > 3] # bigger than three
```

### Some Gotchas


#### Shallow versus Deep Copies

In `R`, assignment usually produces a **deep copy.** In the code below, we create `b` from `a`. If we modify `b`, these changes don't affect `a`. This takes up more memory, but our program is easier to follow as we don't have to keep track of connections between objects. 

```{r, collapse = TRUE}
# in R
a <- c(1,2,3)
b <- a
b[1] <- 999
a # still the same!
```

With Numpy arrays in `Python`, each copy is typically a **shallow copy.** In the code below, `b` is a **reference** for `a`. They both point to the same data in memory. We make a change to `b`, and it *does* affect `a`. This can make the program more confusing, although it can improve computational efficiency. 

```{python, collapse = TRUE}
# in python
a = np.array([1,2,3])
b = a
b[0] = 999
a # two names for the same object in memory
```

If you want a deep copy in `Python`, use `np.copy`.

```{python, collapse = TRUE}
# in python
a = np.array([1,2,3])
b = np.copy(a)
b[0] = 999
a 
```


### How do `R` and `Python` handle missing values?

`R` has `NULL`,  `NaN`, and `NA`. `Python` has `None`, `np.nan`. If your eyes are glazing over already and you're thinking "they all look like the same"--they are not. 

`R`'s `NULL` and `Python`'s `None` are similar. Both represent "nothingness." This is *not* the same as `0`, or an empty string, or `FALSE`/`False`. This is commonly used to detect if a user fails to pass in an argument to a function, or if a function fails to "return" (more on functions in TODO) anything meaningful. 

In `R`, for example, if a function fails to , then it returns a `NULL`. 

```{r, collapse = TRUE, warning=TRUE}
NULL==FALSE
NULL==NULL
doNothingFunc <- function(a){}
thing <- doNothingFunc()
is.null(thing)
typeof(NULL)
```

In `Python`, we have the following.

```{python, collapse = TRUE}
None == False
None == None
def do_nothing_func():
  pass
thing = do_nothing_func()
if thing is None:
  print("thing is None!")
type(None)
```

`NaN` stands for "not a number." It is an object of type `double` in `R`, and type `float` in `Python`. It can come in handy when you have $0/0$ or $\infty / -\infty$.

```{r, collapse = TRUE}
# in R
0/0
Inf/Inf
is.na(0/0)
```
```{python, collapse = TRUE, error = TRUE}
# in Python
0/0
import numpy as np
np.inf/np.inf
np.isnan(np.nan)
```

"NA" is short for "not available." Missing data is a fact of life in data science. Observations are often missing in data sets, or introduced after joining/merging data sets together (more on this in chapter TODO). There are many techniques designed to estimate quantities in the presence of missing data. When you code them up, you'll need to make sure you deal with `NA`s properly. 

```{r, collapse = TRUE}
# in R
babyData <- c(0,-1,9,NA,21)
NA == TRUE 
is.na(babyData)
typeof(NA)
```


Unfortunately `Python`s support of an `NA`-like object is more limited. There is no `NA` object in base `Python`. And often `NaN`s will appear in place of an `NA`. There are a few useful tools, though. The Numpy library offers ["masked arrays"](https://numpy.org/devdocs/reference/maskedarray.html), for one. 

Also, as of version `1.0.0`, the [Pandas library](https://pandas.pydata.org/docs/user_guide/index.html#user-guide) has an experimental `pd.NA` object. However, they [warn](https://pandas.pydata.org/pandas-docs/dev/user_guide/missing_data.html#missing-data-na) that "the behaviour of `pd.NA` can still change without warning." We will discuss `Pandas` in chapter TODO.

```{python, collapse = TRUE}
import numpy as np
import numpy.ma as ma
baby_data = ma.array([0,-1,9,-9999, 21]) # -9999 "stands for" missing
baby_data[3] = ma.masked
np.average(baby_data)
```

```{block, type='rmd-caution'}
Be careful of using extreme values to stand in for what should be an `NA`. Failing to mark the above missing value correctly would lead to extremely wrong calculations!
```

<!---
---------------------------------------------------------------------------
-->

## Numpy's `ndarray`s versus `R`'s matrices and arrays

Sometimes you want a collection of elements that are all the same type, but you want to store them in a two- or three-dimensional structure. For instance, say you need to use matrix multiplication for some linear regression software you're writing, or that you needed to use tensors for a computer vision project you're working on. 

### In `Python`

In `Python`, you could still use arrays for these kinds of tasks. You will be pleased to learn that the Numpy `array`s we discussed earlier are a special case of [Numpy's N-dimensional arrays](https://numpy.org/doc/stable/reference/arrays.ndarray.html). Each array will come with an enormous amount of methods and attributes (more on OOP TODO) attached to it. A few are demonstrated below. 

```{python, collapse = TRUE}
import numpy as np
a = np.array([[1,2],[3,4]], np.float)
a
a.shape
a.ndim
a.dtype
a.max()
a.resize((1,4)) # modification is **in place**
a
```


### In `R`

TODO (cite matloff book)

## `R` lists versus `Python` lists

When you need to store elements in a container, but you can't guarantee that these elements all have the same type, or you can't guarantee that they all have the same size, then you need a `list`. Both `R` and `Python` have lists, but they have some differences.

### Lists In `R`

`list`s are one of the most flexible data types in `R`. You can access individual elements in many different ways, each element can be of different size, and each element can be of a different type. 

```{r, collapse = TRUE}
myList <- list(c(1,2,3), "May 5th, 2021", c(TRUE, TRUE, FALSE))
myList[1] # length-1 list; first element is length 3 vector
myList[[1]] # length-3 vector
```

If you want to extract an element, you need to decide between using single square brackets or double square brackets. The former returns a `list`, while the second returns the type of the individual element.

You can also name the elements of a list. This can lead to more readable code. To see why, examine the example below. The `lm()` function estimates a linear regression model. It returns a `list` with plenty of components. 

```{r, collapse = TRUE, echo=TRUE, results='hide'}
dataSet <- read.csv("data/cars.csv")
results <- lm(log(Horsepower) ~ Type, data = dataSet)
length(results)
names(results)
results$contrasts
results['rank']
results[['terms']]
```


### Lists In `Python`

[`Python` `list`s](https://docs.python.org/3/library/stdtypes.html#lists) are very flexible, too. There are fewer choices for accessing elements of lists in `Python`--you'll most likely end up using the square bracket operator. Elements can be different sizes and types, just like they were with `R` `list`s. 

Unlike in `R`, you can't name elements of lists. If you want a container that allows you to access elements by name, look into `Python` [dictionaries](https://docs.python.org/3/library/stdtypes.html#mapping-types-dict) or Pandas `Series` objects (TODO more about this earlier).

From the example below, you can see that we've been introduced to lists already. We have been constructing Numpy arrays from them.

```{python, collapse = TRUE}
another_list = [np.array([1,2,3]), "May 5th, 2021", True, [42,42]]
another_list[2]
```

## `R` factors and tables versus ?

## `R` data frames versus `Pandas` data frames

As data scientists, most of the time, our data set will be stored as a data frame. https://cran.r-project.org/doc/manuals/r-release/R-lang.html#Data-frame-objects


## Classes in `R` and `Python`

## Exercises

All answers to questions related to `R` should be written in a file named `data_types_exercises.R`. All answers to questions related to `Python` should be written in a file named `data_types_exercises.py`.


1. Which `Python` type is appropriate for each piece of data?

  a. TODO
  b. TODO
  
  
2. In `R`, say you have a vector of prices of some financial asset:

```{R, collapse = TRUE}
prices <- c(100.10, 95.98, 100.01, 99.87)
```

a.
Convert this vector into a vector of *log returns*. Call the variable `log_returns`. If $p_t$ is the price at time $t$, the log return ending at time $t$ is 
$$ r_t = \log \left( \frac{p_t}{p_{t-1}} \right) = \log p_t - \log p_{t-1}$$

b.
Do the same for *arithmetic returns*. These are regular percent changes if you scale by $100$. Call the variable `arith_returns`. The mathematical formula you need is

$$ a_t = \left( \frac{p_t - p_{t-1} }{p_{t-1}} \right) \times 100 $$

3. Assume we are interested in the probability that a normal random variable with mean $5$ and standard deviation $6$ is greater than $6$.

We will make use of the *Monte Carlo* (TODO cite) method below. It is a technique to approximate expectations and probabilities. If $n$ is a large number, then the right hand side of 
$$
\mathbb{P}(X > 6) \approx \frac{1}{n}\sum_{i=1}^n \mathbb{1}(X_i > 6)
$$
is an accurate approximation. 

a. Evaluate this probability exactly in `R` and assign it to the variable `exactExceedanceProb` 

b. Evaluate this probability exactly in `Python` and assign it to the variable `exact_exceedance_prob`

c. In `R`, use the Monte Carlo method to estimate the probability. Use one thousand samples. Assign it to the variable `approxExceedanceProb`

d. In `Python`, use the Monte Carlo method to estimate the probability. Use one thousand samples. Assign it to the variable `approx_exceedance_prob`


4. For a collection of random variables $X_1, \ldots, X_n$, a *covariance matrix* arranges all of the covariances between every possible pair of random variables:

$$
\begin{bmatrix}
\text{Cov}(X_1, X_1) & \text{Cov}(X_1, X_2) & \cdots & \text{Cov}(X_1, X_n) \\
\text{Cov}(X_2, X_1) & \text{Cov}(X_2, X_2) & \cdots & \text{Cov}(X_2, X_n) \\
\vdots & \vdots & \ddots & \vdots\\
\text{Cov}(X_n, X_1) & \text{Cov}(X_n, X_2) & \cdots & \text{Cov}(X_n, X_n) \\
\end{bmatrix}
$$
where 
$$\text{Cov}(X_i, X_j) = \mathbb{E}\left[(X_i - \mathbb{E}[X_i])((X_j - \mathbb{E}[X_j])\right]$$
 is the covariance between $X_i$ and $X_j$ resting in row $i$ and column $j$. 
 
 Using this definition, it is easy to show that $\text{Cov}(X_i, X_i) = \mathbb{E}\left[(X_i - \mathbb{E}[X_i])^2\right] = \text{Var}(X_i)$.

An **exchangeable** covariance matrix for a random vector is one that has all the same variances, and all the same covariances. In other words, it has two unique elements: the diagonal elements should be the same, and the off-diagonals should be the same. 

a. In `R`, generate $10$ $4 \times 4$ exchangeable covariance matrices, each with $2$ as the variance, and have the possible covariances take values in the collection $0,.01,.02, ..., .09.$  Store these $10$ covariance matrices in a three-dimensional array. The first index should be each matrix's row index, the second should be the column index of each matrix, and the third index should be the "layer" or "slice" indicating which of the $10$ matrices you have. Name this array `myCovMats`

b. Do the same thing in `Python`, but call the variable `my_cov_mats`

5. In `R`, read in the `cars.csv` data set using `read.table()` (more on IO in chapter TODO). Find the average `EngineSize`, `Cylinders`, `Horsepower`, `MPG_City`, `MPG_Highway`, `Weight`, `Wheelbase` and `Length` **for each type of vehicle** (i.e. `Hybrid` `Sedan` `Sports`, `SUV`, `Truck` and `Wagon`). Which of these averages is an `NA`? How many observations in that column are missing? 

6. In `Python` (TODO finish this question), read in the `cars.csv` data set using `read.table()` (more on IO in chapter TODO). Find the average `EngineSize`, `Cylinders`, `Horsepower`, `MPG_City`, `MPG_Highway`, `Weight`, `Wheelbase` and `Length` **for each type of vehicle** (i.e. `Hybrid` `Sedan` `Sports`, `SUV`, `Truck` and `Wagon`). Which of these averages is an `NA`? How many observations in that column are missing? 


6.  Here are two lists in `R`:

```{R, collapse = TRUE}
l1 <- list(first="a", second=1)
l2 <- list(first=c(1,2,3), second = "statistics")
```



a. Make a new `list` that is these two lists above "squished together." It has to be length $4$, and each element is one of the elements of $l1$ and $l2$. Call this list `l3`.

b. Delete all the "tags" or "names" of these four elements.

c. Make a `vector` of all the unique single digit numbers in both of the lists. You should end up with the vector with elements `1`, `2`, and `3`.


7.  Here are two `dict`s in `Python`:

```{python, collapse = TRUE}
d1 = { "first" : "a", "second" : 1}
d2 = { "first" : [1,2,3], "second" : "statistics"}
```



a. Make a new `list` that is these two `dict`s above "squished together" (why can't it be another `dict`?) It has to be length $4$, and each value is one of the values of $d1$ and $d2$. Call this list `l3`.


8. How might you explain the difference between `Python` and `R`'s type systems? What do you know about the historical development of these languages that might assist your explanation?


9. Example on underflow and overflow.