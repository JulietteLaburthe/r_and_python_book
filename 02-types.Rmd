# Data Types 

In every programming language, data is stored in different ways. Writing a program that manipulates data requires understanding all of the choices. That is why we must be concerned with the different **types** of data in our `R` and `Python` programs. Different types are suitable for different purposes.

There are similarities between `Python`'s and `R`'s type systems. However, there are may  differences as well. Be prepared for these differences. There are many more of them in this chapter than there were in the previous chapter!

If you're ever unsure what type a variable has, use `type()` (in `Python`) or `typeof()` (in `R`) to query it. 


<!---
---------------------------------------------------------------------------
-->


## Basic Types

Storing an individual piece of information is simple in both languages. However, while `Python` has scalar types, `R`'s situation is a little more complicated (TODO word choice).

### In `Python`

In `Python`, the simplest types we frequently use are `str` (short for string), `int` (short for integer), `float` (short for floating point) and `bool` (short for Boolean). This list is not exhaustive, but these are a good collection to start thinking about. For a complete list of built-in types in `Python`, click [here](https://docs.python.org/3/library/stdtypes.html).

```{python, collapse = TRUE}
print(type('a'), type(1), type(1.3))
```

Strings are useful for processing text data such as names of people/places/things and messages (e.g. texts, tweets and emails). If you are dealing with numbers, you need floating points if you have a number that might have a fractional part after its decimal; otherwise you'll need an integer. Booleans are useful for situations where you need to record whether something is true or false. They are also important to understand for control-flow (TODO which section).

In the next section we will discuss the Numpy library. This library has a [broader collection](https://numpy.org/doc/stable/user/basics.types.html) of basic types. 

#### Type Conversions

We will often have to convert between types in a `Python` program. This is called **type conversion**, and it can be either implicitly or explicitly done. 
For example, `int`s are often implicitly converted to `float`s, so that arithmetic operations work. 
```{python, collapse = TRUE}
my_int = 1
my_float = 3.2
my_sum = my_int + my_float
print("my_int's type", type(my_int))
print("my_float's type", type(my_float))
print(my_sum)
print("my_sum's type", type(my_sum))
```

You might be disappointed if you always count on this behavior, though.
```{python, error = TRUE, collapse=TRUE}
3.2 + "3.2"
```

Explicit conversions occur when we as programmers are explicitly asking `Python` to perform the conversion. You will do this with the functions `int()`, `str()`, `float()`, `bool()`, and the like. 

```{python, collapse = TRUE}
my_date = "5/2/2021"
month_day_year = my_date.split('/')
my_year = int(month_day_year[-1]) 
print('my_year is equal to ', my_year, 'and its type is ', type(my_year))
```

### In `R`

In `R`, the names of these basic types are only slightly different. They are `logical` (instead of `bool`), `integer` (instead of `int`), `double` (instead of `float`)^["double" is short for "double precision floating point." In the programming language `C`, which is what both `R` and `Python` are written in, the programmer has more control on how many decimal points of precision he wants.], and `character` (instead of `str`). There is also `complex` and `raw`, but we will use these less often in this textbook.

```{R, collapse = TRUE}
# cat() is kind of like print()
cat(typeof('a'), typeof(1), typeof(1.3))
```

In this case `R` automatically upgraded `1` to a double. If you wanted to force it to be an integer, you can add a capital "L" to the end of the number.

```{R, collapse = TRUE}
# cat() is kind of like print()
cat(typeof('a'), typeof(1L), typeof(1.3))
```


#### Type Conversions

You can explicitly and implicitly convert types in `R` just as you did in `Python`. Implicit conversion looks like this.

```{R, collapse = TRUE}
myInt = 1
myDouble = 3.2
mySum = myInt + myDouble
print(paste0("my_int's type is ", typeof(myInt)))
print(paste0("my_float's type is ", typeof(myDouble)))
print(mySum)
print(paste0("my_sum's type is ", typeof(mySum)))
```

Explicit conversion can be achieved with functions such as `as.integer`, `as.logical`, `as.double`, etc.

```{R, collapse = TRUE}
print(typeof(1))
print(typeof(as.logical(1)))
```



#### What was the weird thing about `R` you mentioned?

The basic types of `R` are a little different than the basic types of `Python`. `R` uses the same type to store many elements. It does not have any scalar type. On the other hand, `Python` has base types for individual elements, and it uses separate types as containers for storing many elements. In `R`, if you are looking at single number or character string, it's actually a length $1$ `vector`. More information about `vector`s in TODO.

TODO constants versus literals?

<!---
---------------------------------------------------------------------------
-->


## `R` vectors versus `numpy` arrays (and Pandas `Series`)

This section is for describing the data types that let us store collections of elements that all **share the same type**. Data is very commonly stored in this fashion, so this section is quite important. Once we have one of these objects in a program, we will be interested in learning how to extract different subsets of elements, and how vectorization works

### Overview of `R`

I mentioned earlier that `R` does not have scalar types--it just has [**vectors**](https://cran.r-project.org/doc/manuals/r-release/R-lang.html#Vector-objects
). So, whether you want to store one number, or many numbers, you will need a `vector`. 

How do we create one of these? There are many ways. One common is to read in elements from an external data set, perhaps extracting them from a column of a `data.frame`, but we will describe those in section TODO. Here are some examples of generating `vector`s from code instead of external data sets.

```{R, collapse = TRUE}
1:10
seq(1,10,2)
rep(2,5)
c("5/2/2021", "5/3/2021", "5/4/2021")
rnorm(10)
```

`c` is short for "combine". `seq` and `rep` are short for "sequence" and "replicate", respectively. `rnorm` samples normal (or Gaussian) random variables. There is plenty more to learn about these functions, so I encourage you to take a look at their documentation.

### Overview of `Python`

If you want to store many elements of the same type (and size) in `Python`, you will need a Numpy `array`. Numpy is a very highly-regarded third party library [@harris2020array]

There are five ways to create numpy arrays ([source](https://numpy.org/doc/stable/user/basics.creation.html)). Here are some examples that complement the above examples.

```{python, collapse = TRUE}
import numpy as np
np.array([1,2,3])
np.arange(1,12,2)
np.random.normal(size=3)
```

Another choice in `Python` is to use [`Series` object](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas-series). These are made available through the Pandas library. The benefit of these is that they play nicely with Pandas Data frames (TODO link), and that they have more flexibility with accessing elements by name (cite book https://jakevdp.github.io/PythonDataScienceHandbook/03.01-introducing-pandas-objects.html#Series-as-generalized-NumPy-array).

### Vectorization in `R`

An operation is **vectorized** if it applies to all of the elements of a `vector` at once. An operator that is not vectorized can only be applied to individual elements. In that case, the programmer would need to write more code to instruct the function to be applied to all of the elements of a vector. You should prefer writing vectorized code because it is easier to read, and quite often it runs much faster.

Arithmetic (e.g. `+`, `-`, `*`, `/`, `^`, `%%`, `%/%`, etc.) and logical (e.g. `!`, `|`, `&`, `>`, `>=`, `<`, `<=`, `==`, etc.) operators  are commonly applied on single vectors or between two vectors. Numeric vectors are converted to logical vectors if they need to be. Many functions work on vectors **element-wise** as well (except functions like `sum` or `length`, etc.). Operator precedence is important to understand if you seek to minimize your use of parentheses. Here are some examples.

```{r, collapse = TRUE}
(1:3) * (1:3)
(1:3) == rev(1:3)
sin( (2*pi/3)*(1:5))
```

In the last example, there is **recycling** happening. `(2*pi/3)` is taking three length-one vectors and producing another length-one vector. That gets multiplied by length five vector `1:5`. The single element in the length one vector gets recycled so that its value is multiplied by every element of `1:5`. 
This makes sense most of the time, but sometimes it can be tricky. Notice that this does not produce an error--just a warning.
```{r, collapse = TRUE}
(1:3) * (1:4)
```

### Vectorization in `Python`

TODO add pandas series

`Python`'s Numpy library makes extensive use of vectorization as well. Vectorization in Numpy is accomplished with [**universal functions**](https://numpy.org/doc/stable/reference/ufuncs.html), or `ufunc` for short. Some `ufunc`s can be invoked using the same syntax as in `R` (e.g. `+`). You can also refer to function by name (e.g. `np.sum`). Mixing and matching is allowed, too.

`ufunc`s are called *unary* if they take in one array, and *binary* if they take in two. I reproduce a portion of the very nice table found in [@py_ds_handbook] 

| Operator |	Equivalent `ufunc` |
|-----------|-------------------|
`+`	| `np.add`	
`-`	| `np.subtract`	
`-`	| `np.negative`	
`*` |	`np.multiply`	
`/`	| `np.divide`	
`//` |	`np.floor_divide`	
`**`	| `np.power`	
`%` |	`np.mod`

For an exhaustive list of Numpy's universal functions, [click here.](https://numpy.org/doc/stable/reference/ufuncs.html#available-ufuncs) Here are some examples.


```{python, collapse=TRUE}
np.arange(1,4)*np.arange(1,4)
np.zeros(5) > np.arange(-3,2)
np.exp( -.5 * np.linspace(-3, 3, 10)**2) / np.sqrt( 2 * np.pi)
```

Instead of calling it "recycling", `Python` calls it [**broadcasting**](https://numpy.org/devdocs/user/theory.broadcasting.html). It's the same idea as in `R`, but in general, `Python` is stricter and disallows more scenarios. 

### Indexing `vector`s in `R`

It is very common to want to extract or modify a subset of elements in a vector. There are a few ways to do this. All of them involve the square bracket operator (e.g. `[]`). Feel free to retrieve the documentation by typing `?'['`.

```{R, collapse = TRUE}
allElements <- 1:6
allElements[seq(2,6,2)] # extract evens
allElements[-seq(2,6,2)] <- 99 # replace all odds with 99
allElements[allElements > 2] # get nums bigger than 20
```

To access the first element, we use the index `1`. To access the second, we use `2`, and so on. Also, the `-` sign tells `R` to remove elements. Both of these functionalities are *very different* from `Python`, as we will see shortly.

We can use names to access elements elements, too, but only if the elements are named.

```{R, collapse = TRUE}
sillyVec <- c("favorite"=1, "least favorite" = 2)
sillyVec['favorite']
```


### Indexing Numpy arrays

[Indexing Numpy arrays](https://numpy.org/doc/stable/user/basics.indexing.html) is very similar to indexing vectors in `R`. You use the square brackets, and you can do it with logical arrays or index arrays. There are some important differences, though. 

For one, indexing is 0-based in `Python`. The `0`th element is the first element of an array. Another key difference is that the `-` isn't used to remove elements like it is in `R`, but rather to count backwards. Third, using `:`inside square brackets is more flexible in `Python` (e.g. you can get **striding** functionality without using `seq`).

```{python, collapse=TRUE}
one_through_ten = np.arange(1, 11)
one_through_ten[np.array([2,3])]
one_through_ten[1:10:2] # evens
one_through_ten[-2] = 99 # second to last
one_through_ten
one_through_ten[one_through_ten > 3] # bigger than three
```

### Some Gotchas


#### Shallow versus Deep Copies

In `R`, assignment usually produces a **deep copy.** In the code below, we create `b` from `a`. If we modify `b`, these changes don't affect `a`. This takes up more memory, but our program is easier to follow as we don't have to keep track of connections between objects. 

```{r, collapse = TRUE}
# in R
a <- c(1,2,3)
b <- a
b[1] <- 999
a # still the same!
```

With Numpy arrays in `Python`, each copy is typically a **shallow copy.** In the code below, `b` is a **reference** for `a`. They both point to the same data in memory. We make a change to `b`, and it *does* affect `a`. This can make the program more confusing, although it can improve computational efficiency. 

```{python, collapse = TRUE}
# in python
a = np.array([1,2,3])
b = a
b[0] = 999
a # two names for the same object in memory
```

If you want a deep copy in `Python`, use `np.copy`.

```{python, collapse = TRUE}
# in python
a = np.array([1,2,3])
b = np.copy(a)
b[0] = 999
a 
```


### How do `R` and `Python` handle missing values?

`R` has `NULL`,  `NaN`, and `NA`. `Python` has `None`, `np.nan`. If your eyes are glazing over already and you're thinking "they all look like the same"--they are not. 

`R`'s `NULL` and `Python`'s `None` are similar. Both represent "nothingness." This is *not* the same as `0`, or an empty string, or `FALSE`/`False`. This is commonly used to detect if a user fails to pass in an argument to a function, or if a function fails to "return" (more on functions in TODO) anything meaningful. 

In `R`, for example, if a function fails to return anything, then it returns a `NULL`. 

```{r, collapse = TRUE, warning=TRUE}
NULL==FALSE
NULL==NULL
doNothingFunc <- function(a){}
thing <- doNothingFunc()
is.null(thing)
typeof(NULL)
```

In `Python`, we have the following.

```{python, collapse = TRUE}
None == False
None == None
def do_nothing_func():
  pass
thing = do_nothing_func()
if thing is None:
  print("thing is None!")
type(None)
```

`NaN` stands for "not a number." It is an object of type `double` in `R`, and type `float` in `Python`. It can come in handy when you have $0/0$ or $\infty / -\infty$.

```{r, collapse = TRUE}
# in R
0/0
Inf/Inf
is.na(0/0)
```
```{python, collapse = TRUE, error = TRUE}
# in Python
0/0
import numpy as np
np.inf/np.inf
np.isnan(np.nan)
```

"NA" is short for "not available." Missing data is a fact of life in data science. Observations are often missing in data sets, or introduced after joining/merging data sets together (more on this in chapter TODO). There are many techniques designed to estimate quantities in the presence of missing data. When you code them up, you'll need to make sure you deal with `NA`s properly. 

```{r, collapse = TRUE}
# in R
babyData <- c(0,-1,9,NA,21)
NA == TRUE 
is.na(babyData)
typeof(NA)
```


Unfortunately `Python`s support of an `NA`-like object is more limited. There is no `NA` object in base `Python`. And often `NaN`s will appear in place of an `NA`. There are a few useful tools, though. The Numpy library offers ["masked arrays"](https://numpy.org/devdocs/reference/maskedarray.html), for one. 

Also, as of version `1.0.0`, the [Pandas library](https://pandas.pydata.org/docs/user_guide/index.html#user-guide) has an experimental `pd.NA` object. However, they [warn](https://pandas.pydata.org/pandas-docs/dev/user_guide/missing_data.html#missing-data-na) that "the behaviour of `pd.NA` can still change without warning." We will discuss `Pandas` in chapter TODO.

```{python, collapse = TRUE}
import numpy as np
import numpy.ma as ma
baby_data = ma.array([0,-1,9,-9999, 21]) # -9999 "stands for" missing
baby_data[3] = ma.masked
np.average(baby_data)
```

```{block, type='rmd-caution'}
Be careful of using extreme values to stand in for what should be an `NA`. Failing to mark the above missing value correctly would lead to extremely wrong calculations!
```

<!---
---------------------------------------------------------------------------
-->

## Numpy's `ndarray`s versus `R`'s matrices and arrays

Sometimes you want a collection of elements that are all the same type, but you want to store them in a two- or three-dimensional structure. For instance, say you need to use matrix multiplication for some linear regression software you're writing, or that you needed to use tensors for a computer vision project you're working on. 

### In `Python`

In `Python`, you could still use arrays for these kinds of tasks. You will be pleased to learn that the Numpy `array`s we discussed earlier are a special case of [Numpy's N-dimensional arrays](https://numpy.org/doc/stable/reference/arrays.ndarray.html). Each array will come with an enormous amount of [methods](https://numpy.org/doc/stable/reference/arrays.ndarray.html#array-methods) and [attributes](https://numpy.org/doc/stable/reference/arrays.ndarray.html#array-attributes) (more on OOP TODO) attached to it. A few are demonstrated below. 

```{python, collapse = TRUE}
import numpy as np
a = np.array([[1,2],[3,4]], np.float)
a
a.shape
a.ndim
a.dtype
a.max()
a.resize((1,4)) # modification is **in place**
a
```


### In `R`

TODO (cite matloff book)

## `R` lists versus `Python` lists

When you need to store elements in a container, but you can't guarantee that these elements all have the same type, or you can't guarantee that they all have the same size, then you need a `list`. Both `R` and `Python` have lists, but they have plenty of differences.

### Lists In `R`

`list`s are one of the most flexible data types in `R`. You can access individual elements in many different ways, each element can be of different size, and each element can be of a different type. 

```{r, collapse = TRUE}
myList <- list(c(1,2,3), "May 5th, 2021", c(TRUE, TRUE, FALSE))
myList[1] # length-1 list; first element is length 3 vector
myList[[1]] # length-3 vector
```

If you want to extract an element, you need to decide between using single square brackets or double square brackets. The former returns a `list`, while the second returns the type of the individual element.

You can also name the elements of a list. This can lead to more readable code. To see why, examine the example below. The `lm()` function estimates a linear regression model. It returns a `list` with plenty of components. 

```{r, collapse = TRUE, echo=TRUE, results='hide'}
dataSet <- read.csv("data/cars.csv")
results <- lm(log(Horsepower) ~ Type, data = dataSet)
length(results)
names(results)
results$contrasts
results['rank']
results[['terms']]
```


### Lists In `Python`

[`Python` `list`s](https://docs.python.org/3/library/stdtypes.html#lists) are very flexible, too. There are fewer choices for accessing elements of lists in `Python`--you'll most likely end up using the square bracket operator. Elements can be different sizes and types, just like they were with `R` `list`s. 

Unlike in `R`, you can't name elements of lists. If you want a container that allows you to access elements by name, look into `Python` [dictionaries](https://docs.python.org/3/library/stdtypes.html#mapping-types-dict) or Pandas `Series` objects (TODO more about this earlier).

From the example below, you can see that we've been introduced to lists already. We have been constructing Numpy arrays from them.

```{python, collapse = TRUE}
another_list = [np.array([1,2,3]), "May 5th, 2021", True, [42,42]]
another_list[2]
```

## User-defined functions in `R` and `Python`

Why are functions important in statistical programming? In both `R` and `Python` (and every other programming language), functions are used to perform calculations. This is a pretty obvious statement.

This text has already covered how to *use* functions that come to us pre-made. At least we have discussed how to use them in a one-off way--just write the name of the function, write some parentheses after that name, and then plug in any requisite arguments by writing them in a comma-separated way between those two parentheses. This is how it works in both `R` and `Python`. 
In this section we take a look at how to define our own functions. This will help us understand pre-made functions. It will also be useful if we need some functionality that isn't already written for us. 

Writing our own functions is also useful (sometimes it is essential) for "packaging up" computations (more on *functional programming* in TODO). Consider the task of estimating a regression model. Would you want to write that program using only arithmetic operators? Would it be simpler if you could use matrix multiplications? Would you want your function to work on different types of inputs? Would you want it to estimate several regression models and choose the "best" one?

Thankfully, `R` functions are very similar to `Python` functions. In both languages, functions are **first-class objects**. This means that, no matter which of these two languages you're using, functions

- can be passed as arguments to other functions, 
- they can be returned as values from other functions, and 
- they can be assigned to variables and stored in containers [@struc_and_interp]

### Defining `R` Functions

To create a function in `R`, we need another function called `function`. We give the output of `function` a name in the same way we give names to any other variable in `R`, by using the assignment operator `<-`. Here's an example of a toy function called `addOne`. Here `myInput` is a placeholder that refers to whatever the user of the function ends up plugging in. 

```{r, collapse = TRUE}
addOne <- function(myInput){  # define the function
  myOutput <- myInput + 1
  return(myOutput)
}
addOne(41) # call/invoke/use the function 
```

Below the definition, the function is called with an input of `41`. When this happens, the following sequence of events occurs

- The value `41` is assigned to `myInput`
- `myOutput` is given the value `42`
- `42` is returned from the function
- the temporary variables `myInput` and `myOutput` are destroyed. 

We get the desired answer, and all the unnecessary intermediate variables are cleaned up and thrown away. 


### Defining `Python` Functions

To create a function in `Python`, we use the `def` statement (instead of the `function` function in `R`). The desired name of the function comes next. After that, the formal parameters come, comma-separated inside parentheses, just like in `R`. 

Defining a function in `Python` is a little more concise. There is no assignment operator like there is in `R`, there are no curly braces, and `return` isn't a function like it is in `R`, so there is no need to use parentheses after it. There is one addition, though--we need a colon (`:`). 

Here is an example of a toy function called `add_one`.

```{python, collapse = TRUE}
def add_one(my_input):  # define the function
  my_output = my_input + 1
  return my_output
add_one(41) # call/invoke/use the function 
```

Below the definition, the function is called with an input of `41`. When this happens, the following sequence of events occurs

- The value `41` is assigned to `my_input`
- `my_output` is given the value `42`
- `42` is returned from the function
- the temporary variables `my_input` and `my_output` are destroyed. 

We get the desired answer, and all the unnecessary intermediate variables are cleaned up and thrown away. 

### More details on `R`'s user-defined functions


Technically, in `R`, functions are [defined as three things bundled together](https://cran.r-project.org/doc/manuals/r-release/R-lang.html#Function-objects): 

 1. a **formal argument list** (also known as *formals*), 
 2. a **body**, and 
 3. a **parent environment**.

The *formal argument list* is exactly what it sounds like. It is the list of arguments a function takes. You can access a function's formal argument list using the `formals()` function. Note that it is not the *actual* arguments a user will plug in--that isn't knowable at the time the function is created in the first place.

Here is another function that takes a *default* argument called `whichNumber`. If the user of the function doesn't specify how much she wants to add to `myInput`, `addNumber` will use `1` as the default. This default value shows up in the output of `formals(addNumber)`.

```{r, collapse = TRUE}
addNumber <- function(myInput, whichNumber = 1){  
  myOutput <- myInput + whichNumber
  return(myOutput)
}
addNumber(3) # no second argument being provided by the user here
formals(addNumber)
```

The function's *body* is also exactly what it sounds like. It is the work that a function performs. You can access a functions body using the the `body()` function. 

```{r, collapse = TRUE}
addNumber <- function(myInput, whichNumber = 1){  
  myOutput <- myInput + whichNumber
  return(myOutput)
}
body(addNumber)
```

Every function you create also has a  *parent environment*^[Primitive functions are functions that contain no `R` code and are internally implemented in `C`. These are the only type of function in `R` that don't have a parent environment.]. You can get/set this using the `environment()` function. Environments help a function know which variables it is allowed to use and how to use them. The parent environment of a function is where the function was *created*, and it contains variables outside of the body that the function can also use. The rules of which variables a function can use are called *scoping*. When you create functions in `R`, you are primarily using **lexical scoping**. To understand functions well in `R`, these examples are important to understand, so I provide more detail in \@ref(function-scope-in-r).

```{block, type='rmd-details'}
There is a lot more information about environments that isn't provided in this text. For instance, a user-defined function also has [binding, execution, and calling environments associated with it](http://adv-r.had.co.nz/Environments.html#function-envs), and environments are used in creating package namespaces, which are important when two packages each have a function with the same name.
```


### More details on `Python`'s user-defined functions

TODO Python Namespace, Module, Library versus R Environments, Namespaces, Packages

`Python` functions have the same things `R` functions have: a **formal parameter list**, a body, and they are enclosed a TODO. These three concepts are analogous to those in `R`. The names are just a bit different sometimes, and it isn't organized in the same way. 

Below is a table, taken straight from [the documentation](https://docs.python.org/3/reference/datamodel.html#objects-values-and-types), of all each user-defined function's *special attributes*. 

| Attribute |	Meaning |
|-----------|-------------------|
`__doc__`	| The function’s documentation string, or `None` if unavailable; not inherited by subclasses.
`__name__`	| The function’s name.	
`__qualname__`	| The function’s qualified name.	
`__module__` |	The name of the module the function was defined in, or None if unavailable.
`__defaults__`	| A tuple containing default argument values for those arguments that have defaults, or None if no arguments have a default value.
`__code__` |	The code object representing the compiled function body.
`__globals__`	| A reference to the dictionary that holds the function’s global variables — the global namespace of the module in which the function was defined.
`__dict__` |	The namespace supporting arbitrary function attributes.
`__closure__` | `None` or a tuple of cells that contain bindings for the function’s free variables. See below for information on the `cell_contents` attribute.
`__annotations__` | A dict containing annotations of parameters. The keys of the dict are the parameter names, and 'return' for the return annotation, if provided.
`__kwdefaults__` | A dict containing defaults for keyword-only parameters.

So take the  *formal parameter list* of a user-defined function, which is, again, the list of inputs a function takes. Just like in `R`, this is not the *actual* arguments a user will plug in--that isn't knowable at the time the function is created.^[You might have noticed that `Python` uses two different words to prevent confusion--unlike `R`, `Python` uses the word "parameter" (instead of "argument") to refer to the inputs a function takes, and "arguments" to the specific values a user plugs in.] Below we have another function that takes a **default argument** called `which_number`. If the user of the function doesn't specify how much she wants to add to `my_input`, `add_number` will use `1` as the default. This default value can be obtained with `add_number.__defaults__`.

```{python, collapse = TRUE}
def add_number(my_input, which_number = 1):
  my_output = my_input + which_number
  return my_output
add_number(3) # no second argument being provided by the user here
add_number.__code__.co_varnames # this also contains my_output
add_number.__defaults__
```
The code attribute has much more to offer. To see a list of names of all its contents, you can use `dir(add_number.__code__)`.

```{block, type='rmd-details'}
Don't worry if the notation `add_number.__code__` looks strange. The dot (`.`) operator will become more clear in chapter TODO. For now, just think of `__code__` being an object *belonging to* `add_number`. Objects that belong to other objects are called **attributes** in `Python`. The dot operator helps us access attributes *inside* other objects. 
```



### Function Scope in `R`

`R` uses **lexical scoping**.

`R` functions can use variables that are defined in the function body, and variables that were defined in the environment that the function itself was defined in. `R` functions **cannot** necessarily find variables in an environment where the function was *called* in. Code outside the body of a function cannot access variables inside the body of a function.

```{r, collapse = TRUE}
a <- 3
sillyFunction <- function(){
  return(a + 20) 
}
environment(sillyFunction) # the env. it was defined in contains a
sillyFunction()
```

From the point of view of the function, when it attempts to access a variable, it first looks in its own body. In the example below, there are two variables named `a`, but they exist in different environments. Inside the function, the innermost one gets used. Outside the function, the global variable gets used. 

```{r, collapse = TRUE}
a <- 3
sillyFunction <- function(){
  a <- 20
  return(a + 20) 
}
sillyFunction()
print(a)
```

The same concept applies if you create functions within functions. The inner function looks "inside-out" for variables. Below we call `outerFunc()`, which calls `innerFunc()`. `innerFunc()` can refer to the variable `b`, because it lies in the same environment in which `innerFunc()` was created. Interestingly, `innerFunc()` can also refer to the variable `a`, because that variable was captured by `outerFunc`, which provides access to `innerFunc`. 

```{r, collapse = TRUE}
a <- "outside both"
outerFunc <- function(){
  b <- "inside one"
  innerFunc <- function(){
    print(a) 
    print(b)
  }
  return(innerFunc())
}
outerFunc()
```

If we ask `outerFunc` to return the function `innerFunc` (functions are objects!), then we might be surprised to see that `innerFunc()` can still successfully refer to `b`, even though it doesn't exist inside the *calling environment.* But don't be surprised! What matters is what was available when the function was *created*.

```{r, collapse = TRUE}
outerFuncV2 <- function(){
  b <- "inside one"
  innerFunc <- function(){
    print(b)
  }
  return(innerFunc) # note the missing inner parentheses!
}
myFunc <- outerFuncV2() # get a new function
ls(environment(myFunc)) # list all data attached to this function
myFunc()
```

```{block, type='rmd-details'}
Sometimes, in `R`, functions are called **closures** to emphasize that they are capturing variables from the parent environment in which they were created, to emphasize the data that they are bundled with. 
```



### Function Scope in `Python`

`Python` uses **lexical scoping** just like `R`! There's a famous acronym for the concept in `Python`: **LEGB**.

- L: Local, 
- E: Enclosing, 
- G: Global, and 
- B: Built-in.

A `Python` function will search for a variable in these namespaces in this order.^[Functions aren't the only thing that get their own namespace. TODO]. 

"*Local*" refers to variables that are defined inside of the function's block. The function below uses the local `a` over the global one. 

```{python, collapse = TRUE}
a = 3
def silly_function():
  a = 22 # local a
  print("local variables are ", locals())
  return a + 20
silly_function()
silly_function.__code__.co_nlocals # number of local variables
silly_function.__code__.co_varnames # names of local variables
```

"*Enclosing*" refers to variables that were defined in the enclosing namespace. In the example below, there is no local `a` variable for `inner_func`. But there is a global one and one in the enclosing namespace. It chooses the one in the enclosing namespace.

```{python, collapse = TRUE}
a = "outside both"
def outer_func():
  a = "inside one"
  def inner_func():
    print(a)
  return inner_func
my_new_func = outer_func()
my_new_func()
my_new_func.__code__.co_freevars
```

"*Global*" scope contains variables defined in the module-level namespace. In the example below, `a` is a global variable.

```{python, collapse = TRUE}
a = "outside both"
def outer_func():
  b = "inside one"
  def inner_func():
    print(a) 
  inner_func()
outer_func()
```


Just like in `R`, `Python` functions **cannot** necessarily find variables in an environment where the function was *called* in. TODO check Code outside the body of a function cannot access variables inside the body of a function.


### Dynamic Lookup 

In general, it is not a good idea to define functions, in either language, that refer to variables in the global environment/namespace. Consider the code below. 

```{r, collapse=TRUE}
# R
missileLaunchCodesSet <- TRUE
everythingIsSafe <- function(){
  return(!missileLaunchCodesSet)
}
missileLaunchCodesSet <- FALSE
# everythingIsSafe() # what happens if we call it?
```

`everythingIsSafe` is created in the global environment, and the global environment contains a  Boolean variable called `missileLaunchCodesAreSet`. 

As Hadley Wickham writes in [his book](https://adv-r.hadley.nz/functions.html#dynamic-lookup), "[l]exical scoping determines where, but not when to look for values." Imagine sharing some code with a collaborator. Imagine, further, that your collaborator is the subject-matter expert, and knows little about `R` programming. Suppose that he finds a variable changes a global variable in the script. Shouldn't this be a relatively trivial change to the code? Wouldn't it be ideal if no one had to worry about 

There are more situations where this code could be problematic. Consider what could happen if any of the following (very typical) conditions are true:

- you or your collaborators aren't sure what `everythingIsSafe` will return because you don't understand dynamic lookup, or 
- it's difficult to visually keep track of all assignments to `missileLaunchCodesAreSet` (e.g. your script is quite long), or
- you are not running code sequentially (e.g. you are testing chunks at a time instead of `source`ing from scratch over and over again).

Another reason that this could be troublesome is if you define a function that refers to a nonexistent variable. Defining the function won't throw an error. `R` will assume that variable is defined in the global environment. Calling the function might, unless you (accidentally?) defined the variable (later on?).

```{r, collapse = TRUE}
# R
myFunc <- function(){
  return(varigbleNameWithTypo)
}
```

It's the same situation in `Python`. Consider `everything_is_safe`, a function that is analogous to `everythingIsSafe`.

```{python, collapse=TRUE}
# python
missile_launch_codes_set = True
def everything_is_safe():
  return not missile_launch_codes_set

missile_launch_codes_set = False
everything_is_safe()
```

We can also define `my_func`, which is analogous to `myFunc`. Defining this function doesn't throw an error either!

```{python, collapse = TRUE}
# python
def my_func():
  return varigble_name_with_typo
```

So stay away from referring to variables outside the body of your function!

<!-- ```{block, type='rmd-details'} -->
<!-- Sometimes, in `R`, functions are called *closures* to emphasize that they are capturing variables from the parent environment in which they were created.  -->
<!-- ``` -->






## `R` factors and tables versus ?

## `R` data frames versus `Pandas` data frames

As data scientists, most of the time, our data set will be stored as a data frame. https://cran.r-project.org/doc/manuals/r-release/R-lang.html#Data-frame-objects


## Classes in `R` and `Python`

## Exercises

All answers to questions related to `R` should be written in a file named `data_types_exercises.R`. All answers to questions related to `Python` should be written in a file named `data_types_exercises.py`.


1. Which `Python` type is appropriate for each piece of data?

  a. TODO
  b. TODO
  
  
2. In `R`, say you have a vector of prices of some financial asset:

```{R, collapse = TRUE}
prices <- c(100.10, 95.98, 100.01, 99.87)
```

a.
Convert this vector into a vector of *log returns*. Call the variable `log_returns`. If $p_t$ is the price at time $t$, the log return ending at time $t$ is 
$$ r_t = \log \left( \frac{p_t}{p_{t-1}} \right) = \log p_t - \log p_{t-1}$$

b.
Do the same for *arithmetic returns*. These are regular percent changes if you scale by $100$. Call the variable `arith_returns`. The mathematical formula you need is

$$ a_t = \left( \frac{p_t - p_{t-1} }{p_{t-1}} \right) \times 100 $$

3. Assume we are interested in the probability that a normal random variable with mean $5$ and standard deviation $6$ is greater than $6$.

We will make use of the *Monte Carlo* (TODO cite) method below. It is a technique to approximate expectations and probabilities. If $n$ is a large number, then the right hand side of 
$$
\mathbb{P}(X > 6) \approx \frac{1}{n}\sum_{i=1}^n \mathbf{1}(X_i > 6)
$$
is an accurate approximation. If you haven't seen an **indicator** function before, it is defined as 

$$
\mathbf{1}(X_i > 6)
=
\begin{cases}
1 & X_i > 6 \\
0 & X_i \le 6
\end{cases}.
$$

a. Evaluate this probability exactly in `R` and assign it to the variable `exactExceedanceProb` 

b. Evaluate this probability exactly in `Python` and assign it to the variable `exact_exceedance_prob`

c. In `R`, use the Monte Carlo method to estimate the probability. Use one thousand samples. Assign it to the variable `approxExceedanceProb`

d. In `Python`, use the Monte Carlo method to estimate the probability. Use one thousand samples. Assign it to the variable `approx_exceedance_prob`


4. For a collection of random variables $X_1, \ldots, X_n$, a *covariance matrix* arranges all of the covariances between every possible pair of random variables:

$$
\begin{bmatrix}
\text{Cov}(X_1, X_1) & \text{Cov}(X_1, X_2) & \cdots & \text{Cov}(X_1, X_n) \\
\text{Cov}(X_2, X_1) & \text{Cov}(X_2, X_2) & \cdots & \text{Cov}(X_2, X_n) \\
\vdots & \vdots & \ddots & \vdots\\
\text{Cov}(X_n, X_1) & \text{Cov}(X_n, X_2) & \cdots & \text{Cov}(X_n, X_n) \\
\end{bmatrix}
$$
where 
$$\text{Cov}(X_i, X_j) = \mathbb{E}\left[(X_i - \mathbb{E}[X_i])((X_j - \mathbb{E}[X_j])\right]$$
 is the covariance between $X_i$ and $X_j$ resting in row $i$ and column $j$. 
 
 Using this definition, it is easy to show that $\text{Cov}(X_i, X_i) = \mathbb{E}\left[(X_i - \mathbb{E}[X_i])^2\right] = \text{Var}(X_i)$.

An **exchangeable** covariance matrix for a random vector is one that has all the same variances, and all the same covariances. In other words, it has two unique elements: the diagonal elements should be the same, and the off-diagonals should be the same. 

a. In `R`, generate $10$ $4 \times 4$ exchangeable covariance matrices, each with $2$ as the variance, and have the possible covariances take values in the collection $0,.01,.02, ..., .09.$  Store these $10$ covariance matrices in a three-dimensional array. The first index should be each matrix's row index, the second should be the column index of each matrix, and the third index should be the "layer" or "slice" indicating which of the $10$ matrices you have. Name this array `myCovMats`

b. Do the same thing in `Python`, but call the variable `my_cov_mats`

5. In `R`, read in the `cars.csv` data set using `read.table()` (more on IO in chapter TODO). Find the average `EngineSize`, `Cylinders`, `Horsepower`, `MPG_City`, `MPG_Highway`, `Weight`, `Wheelbase` and `Length` **for each type of vehicle** (i.e. `Hybrid` `Sedan` `Sports`, `SUV`, `Truck` and `Wagon`). Which of these averages is an `NA`? How many observations in that column are missing? 

6. In `Python` (TODO finish this question), read in the `cars.csv` data set using `read.table()` (more on IO in chapter TODO). Find the average `EngineSize`, `Cylinders`, `Horsepower`, `MPG_City`, `MPG_Highway`, `Weight`, `Wheelbase` and `Length` **for each type of vehicle** (i.e. `Hybrid` `Sedan` `Sports`, `SUV`, `Truck` and `Wagon`). Which of these averages is an `NA`? How many observations in that column are missing? 


6.  Here are two lists in `R`:

```{R, collapse = TRUE}
l1 <- list(first="a", second=1)
l2 <- list(first=c(1,2,3), second = "statistics")
```



a. Make a new `list` that is these two lists above "squished together." It has to be length $4$, and each element is one of the elements of $l1$ and $l2$. Call this list `l3`.

b. Delete all the "tags" or "names" of these four elements.

c. Make a `vector` of all the unique single digit numbers in both of the lists. You should end up with the vector with elements `1`, `2`, and `3`.


7.  Here are two `dict`s in `Python`:

```{python, collapse = TRUE}
d1 = { "first" : "a", "second" : 1}
d2 = { "first" : [1,2,3], "second" : "statistics"}
```



a. Make a new `list` that is these two `dict`s above "squished together" (why can't it be another `dict`?) It has to be length $4$, and each value is one of the values of $d1$ and $d2$. Call this list `l3`.


8. How might you explain the difference between `Python` and `R`'s type systems? What do you know about the historical development of these languages that might assist your explanation?


9. Example on underflow and overflow.